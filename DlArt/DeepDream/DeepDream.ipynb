{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCMqzy7BNbG9"
   },
   "source": [
    "# <center> Deep Dream </center>\n",
    "\n",
    "<center>This notebook is a short version of https://www.tensorflow.org/tutorials/generative/deepdream</center>\n",
    "<center>Copyright 2019 The TensorFlow Authors. </center>\n",
    "<center>Licensed under the Apache License, Version 2.0 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPDKhwPcNbG7"
   },
   "source": [
    "This tutorial contains a minimal implementation of DeepDream, as described in this [blog post](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) by Alexander Mordvintsev.\n",
    "\n",
    "DeepDream is an experiment that visualizes the patterns learned by a neural network. Similar to when a child watches clouds and tries to interpret random shapes, DeepDream over-interprets and enhances the patterns it sees in an image.\n",
    "\n",
    "It does so by forwarding an image through the network, then calculating the gradient of the image with respect to the activations of a particular layer. The image is then modified to increase these activations, enhancing the patterns seen by the network, and resulting in a dream-like image. This process was dubbed \"Inceptionism\" (a reference to [InceptionNet](https://arxiv.org/pdf/1409.4842.pdf), and the [movie](https://en.wikipedia.org/wiki/Inception) Inception).\n",
    "\n",
    "Let's demonstrate how you can make a neural network \"dream\" and enhance the surreal patterns it sees in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Sc5Yq_Rgxreb"
   },
   "outputs": [],
   "source": [
    "#@title  Import Python libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import PIL.Image    \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/DlArt/DeepDream/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "pKBVjks1ks3o"
   },
   "outputs": [],
   "source": [
    "#@title Choose an Image from Internet or from Drive \n",
    "#@markdown To load file from Drive, upload it first to folder 'DeepDream'\n",
    "\n",
    "#@markdown Choose one option {url or image_name} and remove any input from the other field\n",
    "\n",
    "dir = \"/content/drive/My Drive/DlArt/DeepDream/\"\n",
    "url = \"\" #@param {type: \"string\"}\n",
    "image_name = \"J.jpeg\" #@param {type: \"string\"}\n",
    "\n",
    "if url:\n",
    "  name = url.split('/')[-1]\n",
    "  img_path = tf.keras.utils.get_file(name, origin=url)\n",
    "elif image_name:\n",
    "  img_path =  dir + image_name\n",
    "\n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(image_path, max_dim=None):\n",
    "  img = PIL.Image.open(image_path)\n",
    "  if max_dim:\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "  return np.array(img)\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "  img = 255*(img + 1.0)/2.0\n",
    "  return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "  display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "\n",
    "# Downsizing the image makes it easier to work with.\n",
    "original_img = download(img_path, max_dim=500)\n",
    "show(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "# Compute Loss\n",
    "def calc_loss(img, model):\n",
    "  # Pass forward the image through the model to retrieve the activations.\n",
    "  # Converts the image into a batch of size 1.\n",
    "  img_batch = tf.expand_dims(img, axis=0)\n",
    "  layer_activations = model(img_batch)\n",
    "  if len(layer_activations) == 1:\n",
    "    layer_activations = [layer_activations]\n",
    "\n",
    "  losses = []\n",
    "  for act in layer_activations:\n",
    "    loss = tf.math.reduce_mean(act)\n",
    "    losses.append(loss)\n",
    "\n",
    "  return  tf.reduce_sum(losses)\n",
    "\n",
    "# Shift image \n",
    "def random_roll(img, maxroll):\n",
    "  # Randomly shift the image to avoid tiled boundaries.\n",
    "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
    "  img_rolled = tf.roll(img, shift=shift, axis=[0,1])\n",
    "  return shift, img_rolled\n",
    "\n",
    "# Gradient ascent\n",
    "class DeepDream(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "  )\n",
    "  def __call__(self, img, steps, step_size):\n",
    "      print(\"Tracing\")\n",
    "      loss = tf.constant(0.0)\n",
    "      for n in tf.range(steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "          # This needs gradients relative to `img`\n",
    "          # `GradientTape` only watches `tf.Variable`s by default\n",
    "          tape.watch(img)\n",
    "          loss = calc_loss(img, self.model)\n",
    "\n",
    "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "        gradients = tape.gradient(loss, img)\n",
    "\n",
    "        # Normalize the gradients.\n",
    "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "        \n",
    "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "        img = img + gradients*step_size\n",
    "        img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      return loss, img\n",
    "\n",
    "\n",
    "# Gradient for tiles of an image\n",
    "class TiledGradients(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[2], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
    "  )\n",
    "  def __call__(self, img, img_size, tile_size=512):\n",
    "    shift, img_rolled = random_roll(img, tile_size)\n",
    "\n",
    "    # Initialize the image gradients to zero.\n",
    "    gradients = tf.zeros_like(img_rolled)\n",
    "    \n",
    "    # Skip the last tile, unless there's only one tile.\n",
    "    xs = tf.range(0, img_size[1], tile_size)[:-1]\n",
    "    if not tf.cast(len(xs), bool):\n",
    "      xs = tf.constant([0])\n",
    "    ys = tf.range(0, img_size[0], tile_size)[:-1]\n",
    "    if not tf.cast(len(ys), bool):\n",
    "      ys = tf.constant([0])\n",
    "\n",
    "    for x in xs:\n",
    "      for y in ys:\n",
    "        # Calculate the gradients for this tile.\n",
    "        with tf.GradientTape() as tape:\n",
    "          # This needs gradients relative to `img_rolled`.\n",
    "          # `GradientTape` only watches `tf.Variable`s by default.\n",
    "          tape.watch(img_rolled)\n",
    "\n",
    "          # Extract a tile out of the image.\n",
    "          img_tile = img_rolled[y:y+tile_size, x:x+tile_size]\n",
    "          loss = calc_loss(img_tile, self.model)\n",
    "\n",
    "        # Update the image gradients for this tile.\n",
    "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
    "\n",
    "    # Undo the random shift applied to the image and its gradients.\n",
    "    gradients = tf.roll(gradients, shift=-shift, axis=[0,1])\n",
    "\n",
    "    # Normalize the gradients.\n",
    "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "    return gradients \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "08KB502ONbGt"
   },
   "outputs": [],
   "source": [
    "#@title Load Pre-trained model\n",
    "\n",
    "\n",
    "# load model\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ywy8_NRMm96I"
   },
   "outputs": [],
   "source": [
    "#@title Choose layers \n",
    "\n",
    "#@markdown You can choose from layers mixed0,...., mixed10. \n",
    "\n",
    "#@markdown  Ex: [ 'mixed0'] or [ 'mixed0', 'mixed2', 'mixed10'] etc.\n",
    "\n",
    "# Maximize the activations of these layers\n",
    "names = [ 'mixed1'] #@param {type: \"raw\"}\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "M3Mm8MLCptfY"
   },
   "outputs": [],
   "source": [
    "#@title Train model\n",
    "\n",
    "deepdream = DeepDream(dream_model)\n",
    "get_tiled_gradients = TiledGradients(dream_model)\n",
    "\n",
    "# Put all together\n",
    "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
    "                                octaves=range(-2,3), octave_scale=1.3):\n",
    "  base_shape = tf.shape(img)\n",
    "  img = tf.keras.utils.img_to_array(img)\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "  initial_shape = img.shape[:-1]\n",
    "  img = tf.image.resize(img, initial_shape)\n",
    "  for octave in octaves:\n",
    "    # Scale the image based on the octave\n",
    "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "    new_size = tf.cast(new_size, tf.int32)\n",
    "    img = tf.image.resize(img, new_size)\n",
    "\n",
    "    for step in range(steps_per_octave):\n",
    "      gradients = get_tiled_gradients(img, new_size)\n",
    "      img = img + gradients*step_size\n",
    "      img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      if step % 10 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        show(deprocess(img))\n",
    "        print (\"Octave {}, Step {}\".format(octave, step))\n",
    "    \n",
    "  result = deprocess(img)\n",
    "  return result\n",
    "\n",
    "img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
    "base_shape = tf.shape(tf.constant(np.array(original_img)))[:-1]\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "img = tf.image.resize(img, base_shape)\n",
    "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "s2hAFkN_lQof"
   },
   "outputs": [],
   "source": [
    "#@title Save image\n",
    "\n",
    "img_name = img_path.split(\"/\")[-1].split(\".\")[-2]\n",
    "tf.keras.utils.save_img(dir + img_name + '_' + '-'.join(names) + '.jpeg', img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepDream.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb",
     "timestamp": 1648568022046
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
